{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1313 entries, 0 to 1312\n",
      "Data columns (total 11 columns):\n",
      "row.names    1313 non-null int64\n",
      "pclass       1313 non-null object\n",
      "survived     1313 non-null int64\n",
      "name         1313 non-null object\n",
      "age          633 non-null float64\n",
      "embarked     821 non-null object\n",
      "home.dest    754 non-null object\n",
      "room         77 non-null object\n",
      "ticket       69 non-null object\n",
      "boat         347 non-null object\n",
      "sex          1313 non-null object\n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 112.9+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1313 entries, 0 to 1312\n",
      "Data columns (total 3 columns):\n",
      "pclass    1313 non-null object\n",
      "age       1313 non-null float64\n",
      "sex       1313 non-null object\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 30.9+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\DeepMind\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7811550151975684\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        died       0.91      0.78      0.84       236\n",
      "   survivied       0.58      0.80      0.67        93\n",
      "\n",
      "    accuracy                           0.78       329\n",
      "   macro avg       0.74      0.79      0.75       329\n",
      "weighted avg       0.81      0.78      0.79       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "titanic = pd.read_csv('http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt')\n",
    "titanic.head()\n",
    "titanic.info()\n",
    "X = titanic[['pclass','age','sex']]\n",
    "y = titanic['survived']\n",
    "X['age'].fillna(X['age'].mean(),inplace=True)\n",
    "X.info()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=33)\n",
    "X_train = X_train.to_dict(orient='record')\n",
    "X_test = X_test.to_dict(orient='record')\n",
    "#将非数值型数据转换为数值型数据\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "clf = Pipeline([('vecd',DictVectorizer(sparse=False)),('dtc',DecisionTreeClassifier())])\n",
    "vec = DictVectorizer(sparse=False)\n",
    " \n",
    "clf.fit(X_train,y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print (clf.score(X_test,y_test))\n",
    "print(classification_report(y_predict,y_test,target_names=['died','survivied']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  36 | elapsed:   56.0s remaining:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:   56.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 17s\n",
      "{'svc__C': 10.0, 'svc__gamma': 0.1, 'vect__analyzer': 'word'} 0.7906666666666666\n",
      "0.8226666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "news = fetch_20newsgroups(subset='all')\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(news.data[:3000],news.target[:3000],test_size=0.25,random_state=33)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec = TfidfVectorizer()\n",
    "X_count_train = vec.fit_transform(X_train)\n",
    "X_count_test = vec.transform(X_test)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "#使用pipeline简化系统搭建流程，将文本抽取与分类器模型串联起来\n",
    "clf = Pipeline([\n",
    "    ('vect',TfidfVectorizer(stop_words='english')),('svc',SVC())\n",
    "])\n",
    "# 注意，这里经pipeline进行特征处理、SVC模型训练之后，得到的直接就是训练好的分类器clf\n",
    " \n",
    "parameters = {\n",
    "    'svc__gamma':np.logspace(-2,1,4),\n",
    "    'svc__C':np.logspace(-1,1,3),\n",
    "    'vect__analyzer':['word']\n",
    "}\n",
    " \n",
    "#n_jobs=-1代表使用计算机的全部CPU\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(clf,parameters,verbose=2,refit=True,cv=3,n_jobs=-1)\n",
    " \n",
    "%time _=gs.fit(X_train,y_train)\n",
    "print (gs.best_params_,gs.best_score_)\n",
    "print (gs.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可加入Pipeline的自定义变换\n",
    "\n",
    "## Part 1 步骤\n",
    "\n",
    "首先，需要sklearn.base中的两个类BaseEstimator和TransformerMixin\n",
    "\n",
    "其次，定义自定义变换继承上述两个类，如class CustomFunction(BaseEstimator,TransformerMixin)\n",
    "\n",
    "最后，在自定义变换中定义fit和transform函数\n",
    "\n",
    "## Part 2 实例\n",
    "\n",
    "目标：对于某个含有10个特征的数据集，现在想找到最佳的特征组合使识别率最高，使识别率最高\n",
    "\n",
    "说明：为了达到这个目标，就是采用GridSearchCV的方法，根据CV得分，直接挑选出最佳的特征组合。因此需要构建一个Pipeline能够放入GridSearchCV中。但是，光构建Pipeline还不够，还需要定义一个能够加入Pipeline的选取特定特征组合的变换\n",
    "\n",
    "以下为代码实例：\n",
    "\n",
    "- 构建特征组合变换SelectRowTransformer\n",
    "\n",
    "- 生成数据make_classification\n",
    "\n",
    "- 构建Pipeline\n",
    "\n",
    "- 网格搜素GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 10) (200,)\n",
      "Fitting 3 folds for each of 5115 candidates, totalling 15345 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1689 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 6689 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 13689 tasks      | elapsed:   15.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳CV得分:0.82, 最佳得分对应的特征组合:(0, 1, 5, 9), SVC-C:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 15345 out of 15345 | elapsed:   16.8s finished\n",
      "D:\\DeepMind\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "D:\\DeepMind\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from itertools import combinations \n",
    "\n",
    "class SelectRowTransformer(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,comb_idx = [0,]):\n",
    "        self.comb_idx = comb_idx\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X,y =None):\n",
    "        return X[:,self.comb_idx].copy()\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    __spec__ = None\n",
    "    K = 10\n",
    "    data, label = make_classification(n_samples=200, n_informative=4,n_redundant=0,\n",
    "                                      random_state=223,n_features=K)\n",
    "    print(data.shape, label.shape)\n",
    "    pipe = Pipeline([\n",
    "            ('Comb',SelectRowTransformer() ),\n",
    "            ('SVC',LinearSVC() ),\n",
    "            ])   \n",
    "    param = { \n",
    "            'Comb__comb_idx':[i for j in range(K) for i in combinations(range(K),j+1)],\n",
    "            'SVC__C':[2**(f-2) for f in range(5)]\n",
    "            }   \n",
    "    grid = GridSearchCV(pipe,param,cv=3,verbose=1,n_jobs=-1)\n",
    "    grid.fit(data,label)\n",
    "    print( '最佳CV得分:{0}, 最佳得分对应的特征组合:{1}, SVC-C:{2}'.format(grid.best_score_,\n",
    "          grid.best_params_['Comb__comb_idx'],grid.best_params_['SVC__C']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
